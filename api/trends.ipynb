{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l55djIUa1DKm"
      },
      "outputs": [],
      "source": [
        "#!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u39eK1PMzNx3"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import nltk\n",
        "import pymorphy2\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWA4Iw400v5H"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = stopwords.words('russian')\n",
        "stop_words.extend(['который', 'https', 'также', 'другой', 'которые', 'которым', 'которых', 'которая', 'которому', 'каждый'])\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQWX0goy0v-Y"
      },
      "outputs": [],
      "source": [
        "total_last_week = pd.read_csv(\"/content/total_last_week.csv\", sep = '\\t', error_bad_lines=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "prer0klj0PA3"
      },
      "outputs": [],
      "source": [
        "with open('/content/frequency_dict_half_of_the_year.pkl', 'rb') as f:\n",
        "    frequency_dict_half_of_the_year = pickle.load(f)\n",
        "\n",
        "with open('/content/frequency_dict_last_week.pkl', 'rb') as f:\n",
        "    frequency_dict_last_week = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0CWsWKbr0PKw"
      },
      "outputs": [],
      "source": [
        "general_dict = dict()\n",
        "for key, value in frequency_dict_last_week.items():\n",
        "  if key in frequency_dict_half_of_the_year:\n",
        "    general_dict[key] = value / frequency_dict_half_of_the_year[key]\n",
        "sorted_general_dict = sorted(general_dict.items(), key=lambda x: x[1], reverse = True)[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nQmqND3A0PNj"
      },
      "outputs": [],
      "source": [
        "final_search = []\n",
        "for elem in sorted_general_dict:\n",
        "  final_search.append(elem[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xPmwvW7n0kOP"
      },
      "outputs": [],
      "source": [
        "def find_and_return_article():\n",
        "  trend_result = []\n",
        "  for trend_word in final_search:\n",
        "    trend_word_dictionary = dict()\n",
        "    for counter in range(total_last_week.shape[0]):\n",
        "      text = total_last_week.MESSAGE[counter]\n",
        "      if type(text) != float:\n",
        "          tokens = nltk.word_tokenize(text)   \n",
        "          filtered_text = [word.lower() for word in tokens if word.lower() not in stop_words] \n",
        "          final_text = []\n",
        "          for word in filtered_text:\n",
        "            if word.isalpha() and len(word) > 4:\n",
        "              p = morph.parse(word)[0]\n",
        "              final_text.append(p.normal_form)\n",
        "            else:\n",
        "              continue\n",
        "          if trend_word in final_text:\n",
        "            trend_word_dictionary[counter] = final_text.count(trend_word)\n",
        "    trend_result.append(sorted(trend_word_dictionary.items(), key=lambda x: x[1], reverse = True)[0])\n",
        "  return trend_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CfBXBI4K0kQx"
      },
      "outputs": [],
      "source": [
        "trend_result = find_and_return_article()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q3hV3LWh0kTH"
      },
      "outputs": [],
      "source": [
        "general_trend_collection = []\n",
        "for trend_index in trend_result:\n",
        "  text = re.sub(' - РИА Новости', '', total_last_week.MESSAGE[trend_index[0]])\n",
        "  text = re.sub(' – РИА Новости', '', text)\n",
        "  general_trend_collection.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X9etXVkK0kVl"
      },
      "outputs": [],
      "source": [
        "def write_to_json():\n",
        "  items = []\n",
        "  for index in range(len(general_trend_collection)):\n",
        "    items.append(\n",
        "          {\n",
        "              \"id\": index,\n",
        "              \"text_of_the_article\": general_trend_collection[index]\n",
        "          }\n",
        "      )\n",
        "  with open('trend_news.json', 'w') as file:\n",
        "    json.dump(items, file, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kasuIfMZ0kYE"
      },
      "outputs": [],
      "source": [
        "write_to_json()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
